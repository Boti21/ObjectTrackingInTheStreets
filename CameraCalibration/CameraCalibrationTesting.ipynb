{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b80db758",
   "metadata": {},
   "source": [
    "# This file is for testing the camera calibraiont pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d079203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70aca251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 - Configuration\n",
    "square_size = 0.1  # meters\n",
    "\n",
    "chessboard_sizes = {\n",
    "    'board1': (11, 7),\n",
    "    'board2': (5, 7),\n",
    "    'board3': (7, 5),\n",
    "}\n",
    "\n",
    "# All boards have the same square size\n",
    "square_sizes = {name: square_size for name in chessboard_sizes}\n",
    "\n",
    "# Termination criteria for sub-pixel refinement\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# Prepare object points for each board type\n",
    "objp_templates = {}\n",
    "for name, size in chessboard_sizes.items():\n",
    "    objp = np.zeros((size[0] * size[1], 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:size[0], 0:size[1]].T.reshape(-1, 2) * square_sizes[name]\n",
    "    objp_templates[name] = objp\n",
    "\n",
    "# Storage for calibration data\n",
    "all_objpoints = []\n",
    "all_imgpoints_left = []\n",
    "all_imgpoints_right = []\n",
    "\n",
    "# Create output directory for logging\n",
    "output_dir = Path(\"calibration_debug\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Configuration loaded successfully\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fd5fdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 19 image pairs\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 - Load images\n",
    "raw_path = \"../data/34759_final_project_raw/\"\n",
    "left_raw_path = raw_path + \"calib/image_02/data/\"\n",
    "right_raw_path = raw_path + \"calib/image_03/data/\"\n",
    "\n",
    "left_images = sorted(glob.glob(left_raw_path + '*.png'))\n",
    "right_images = sorted(glob.glob(right_raw_path + '*.png'))\n",
    "\n",
    "if len(left_images) != len(right_images):\n",
    "    print(f\"Error: Mismatch! {len(left_images)} left vs {len(right_images)} right\")\n",
    "else:\n",
    "    print(f\"Successfully loaded {len(left_images)} image pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f372ebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 - Detection function with better logic\n",
    "def detect_multiple_chessboards(gray_img, img_color, chessboard_sizes, \n",
    "                                 objp_templates, criteria, \n",
    "                                 side_name=\"\", img_idx=0, save_debug=True):\n",
    "    \"\"\"\n",
    "    Detect multiple chessboards in a single image.\n",
    "    Returns list of object points and corner points.\n",
    "    \"\"\"\n",
    "    objpoints_found = []\n",
    "    corners_found = []\n",
    "    boards_info = []\n",
    "    \n",
    "    # Create a mask to black out already-found boards\n",
    "    mask = np.ones_like(gray_img) * 255\n",
    "    debug_img = img_color.copy()\n",
    "    \n",
    "    # Try each board size\n",
    "    for board_name, board_size in chessboard_sizes.items():\n",
    "        max_attempts = 10  # Prevent infinite loops\n",
    "        attempts = 0\n",
    "        \n",
    "        while attempts < max_attempts:\n",
    "            attempts += 1\n",
    "            \n",
    "            # Apply mask to ignore already-found regions\n",
    "            masked_gray = cv2.bitwise_and(gray_img, mask)\n",
    "            \n",
    "            # Detect chessboard\n",
    "            flags = cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_NORMALIZE_IMAGE\n",
    "            ret, corners = cv2.findChessboardCornersSB(\n",
    "                masked_gray, board_size, flags\n",
    "            )\n",
    "            \n",
    "            if ret and corners is not None:\n",
    "                # Refine corners for better accuracy\n",
    "                #corners_refined = cv2.cornerSubPix(\n",
    "                #    gray_img, corners, (11, 11), (-1, -1), criteria\n",
    "                #)\n",
    "                corners_refined = corners\n",
    "                \n",
    "                objpoints_found.append(objp_templates[board_name])\n",
    "                corners_found.append(corners_refined)\n",
    "                \n",
    "                # Get bounding box and expand it slightly\n",
    "                x_coords = corners_refined[:, 0, 0]\n",
    "                y_coords = corners_refined[:, 0, 1]\n",
    "                \n",
    "                x_min, x_max = int(x_coords.min()), int(x_coords.max())\n",
    "                y_min, y_max = int(y_coords.min()), int(y_coords.max())\n",
    "                \n",
    "                # Expand by 10% to ensure we mask the whole board\n",
    "                margin_x = int((x_max - x_min) * 0.1)\n",
    "                margin_y = int((y_max - y_min) * 0.1)\n",
    "                \n",
    "                x_min = max(0, x_min - margin_x)\n",
    "                x_max = min(mask.shape[1], x_max + margin_x)\n",
    "                y_min = max(0, y_min - margin_y)\n",
    "                y_max = min(mask.shape[0], y_max + margin_y)\n",
    "                \n",
    "                # Black out this region in the mask\n",
    "                mask[y_min:y_max, x_min:x_max] = 0\n",
    "                \n",
    "                # Draw on debug image\n",
    "                cv2.drawChessboardCorners(debug_img, board_size, \n",
    "                                         corners_refined, True)\n",
    "                cv2.rectangle(debug_img, (x_min, y_min), (x_max, y_max),\n",
    "                            (0, 255, 0), 3)\n",
    "                \n",
    "                boards_info.append({\n",
    "                    'name': board_name,\n",
    "                    'size': board_size,\n",
    "                    'bbox': (x_min, y_min, x_max, y_max)\n",
    "                })\n",
    "                \n",
    "                print(f\"  ✓ Found {board_name} {board_size}\")\n",
    "            else:\n",
    "                # No more boards of this size\n",
    "                break\n",
    "    \n",
    "    # Save debug image\n",
    "    if save_debug and boards_info:\n",
    "        output_path = output_dir / f\"img_{img_idx:03d}_{side_name}.jpg\"\n",
    "        cv2.imwrite(str(output_path), debug_img)\n",
    "    \n",
    "    return objpoints_found, corners_found, boards_info, debug_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9e0b3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting calibration image processing...\n",
      "============================================================\n",
      "\n",
      "Processing pair 1/19: 0000000000.png\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✗ Board count mismatch: 2 left vs 7 right\n",
      "\n",
      "Processing pair 2/19: 0000000001.png\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✗ Board count mismatch: 2 left vs 7 right\n",
      "\n",
      "Processing pair 3/19: 0000000002.png\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✗ Board count mismatch: 2 left vs 7 right\n",
      "\n",
      "Processing pair 4/19: 0000000003.png\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✗ Board count mismatch: 2 left vs 7 right\n",
      "\n",
      "Processing pair 5/19: 0000000004.png\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✗ Board count mismatch: 2 left vs 7 right\n",
      "\n",
      "Processing pair 6/19: 0000000005.png\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✗ Board count mismatch: 2 left vs 7 right\n",
      "\n",
      "Processing pair 7/19: 0000000006.png\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✗ Board count mismatch: 2 left vs 7 right\n",
      "\n",
      "Processing pair 8/19: 0000000007.png\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✗ Board count mismatch: 2 left vs 7 right\n",
      "\n",
      "Processing pair 9/19: 0000000008.png\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✗ Board count mismatch: 2 left vs 7 right\n",
      "\n",
      "Processing pair 10/19: 0000000009.png\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✗ Board count mismatch: 2 left vs 7 right\n",
      "\n",
      "Processing pair 11/19: 0000000010.png\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✗ Board count mismatch: 2 left vs 1 right\n",
      "\n",
      "Processing pair 12/19: 0000000011.png\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✗ Board count mismatch: 1 left vs 7 right\n",
      "\n",
      "Processing pair 13/19: 0000000012.png\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✗ Board count mismatch: 2 left vs 7 right\n",
      "\n",
      "Processing pair 14/19: 0000000013.png\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✗ Board count mismatch: 2 left vs 7 right\n",
      "\n",
      "Processing pair 15/19: 0000000014.png\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✗ Board count mismatch: 2 left vs 7 right\n",
      "\n",
      "Processing pair 16/19: 0000000015.png\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✗ Board count mismatch: 2 left vs 7 right\n",
      "\n",
      "Processing pair 17/19: 0000000016.png\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✗ Board count mismatch: 2 left vs 7 right\n",
      "\n",
      "Processing pair 18/19: 0000000017.png\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✗ Board count mismatch: 2 left vs 7 right\n",
      "\n",
      "Processing pair 19/19: 0000000018.png\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✓ Found board2 (5, 7)\n",
      "  ✗ Board count mismatch: 2 left vs 7 right\n",
      "\n",
      "============================================================\n",
      "Processing complete!\n",
      "  Successful pairs: 0\n",
      "  Failed pairs: 19\n",
      "  Total corner points: 0\n",
      "\n",
      "Debug images saved to: /Users/boti/Library/Mobile Documents/com~apple~CloudDocs/Uni/DTU/1/PfAS/ObjectTrackingInTheStreets/CameraCalibration/calibration_debug\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 - Main detection loop with visualization\n",
    "print(\"Starting calibration image processing...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "successful_pairs = 0\n",
    "failed_pairs = 0\n",
    "\n",
    "for i in range(len(left_images)):\n",
    "    print(f\"\\nProcessing pair {i+1}/{len(left_images)}: {Path(left_images[i]).name}\")\n",
    "    \n",
    "    # Load images\n",
    "    img_left = cv2.imread(left_images[i])\n",
    "    img_right = cv2.imread(right_images[i])\n",
    "    \n",
    "    if img_left is None or img_right is None:\n",
    "        print(f\"  ✗ Failed to load images\")\n",
    "        failed_pairs += 1\n",
    "        continue\n",
    "    \n",
    "    gray_left = cv2.cvtColor(img_left, cv2.COLOR_BGR2GRAY)\n",
    "    gray_right = cv2.cvtColor(img_right, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect boards in both images\n",
    "    objpoints_left, corners_left, info_left, debug_left = detect_multiple_chessboards(\n",
    "        gray_left, img_left, chessboard_sizes, objp_templates, \n",
    "        criteria, \"left\", i, save_debug=True\n",
    "    )\n",
    "    \n",
    "    objpoints_right, corners_right, info_right, debug_right = detect_multiple_chessboards(\n",
    "        gray_right, img_right, chessboard_sizes, objp_templates,\n",
    "        criteria, \"right\", i, save_debug=True\n",
    "    )\n",
    "    \n",
    "    # Must find same number of boards in both images\n",
    "    if len(objpoints_left) != len(objpoints_right) or len(objpoints_left) == 0:\n",
    "        print(f\"  ✗ Board count mismatch: {len(objpoints_left)} left vs {len(objpoints_right)} right\")\n",
    "        failed_pairs += 1\n",
    "        \n",
    "        # Save comparison image\n",
    "        comparison = np.hstack([debug_left, debug_right])\n",
    "        cv2.imwrite(str(output_dir / f\"FAILED_pair_{i:03d}.jpg\"), comparison)\n",
    "        continue\n",
    "    \n",
    "    # Check that boards match (same sizes)\n",
    "    sizes_match = all(\n",
    "        info_left[j]['size'] == info_right[j]['size'] \n",
    "        for j in range(len(info_left))\n",
    "    )\n",
    "    \n",
    "    if not sizes_match:\n",
    "        print(f\"  ✗ Board sizes don't match between left and right\")\n",
    "        failed_pairs += 1\n",
    "        continue\n",
    "    \n",
    "    # Success! Concatenate all boards found in this image pair\n",
    "    all_objpoints.append(np.vstack(objpoints_left))\n",
    "    all_imgpoints_left.append(np.vstack(corners_left))\n",
    "    all_imgpoints_right.append(np.vstack(corners_right))\n",
    "    \n",
    "    successful_pairs += 1\n",
    "    print(f\"  ✓ SUCCESS: {len(objpoints_left)} boards detected and matched\")\n",
    "    \n",
    "    # Save side-by-side comparison\n",
    "    comparison = np.hstack([debug_left, debug_right])\n",
    "    cv2.imwrite(str(output_dir / f\"SUCCESS_pair_{i:03d}.jpg\"), comparison)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Processing complete!\")\n",
    "print(f\"  Successful pairs: {successful_pairs}\")\n",
    "print(f\"  Failed pairs: {failed_pairs}\")\n",
    "print(f\"  Total corner points: {sum(pts.shape[0] for pts in all_objpoints)}\")\n",
    "print(f\"\\nDebug images saved to: {output_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54305743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 - Individual camera calibration\n",
    "if len(all_objpoints) < 3:\n",
    "    print(\"ERROR: Not enough successful calibration images!\")\n",
    "    print(\"Need at least 3, got\", len(all_objpoints))\n",
    "else:\n",
    "    img_shape = gray_left.shape[::-1]  # (width, height)\n",
    "    \n",
    "    print(\"Calibrating left camera...\")\n",
    "    ret_l, mtx_l, dist_l, rvecs_l, tvecs_l = cv2.calibrateCamera(\n",
    "        all_objpoints, all_imgpoints_left, img_shape, None, None\n",
    "    )\n",
    "    print(f\"  RMS error: {ret_l:.4f}\")\n",
    "    \n",
    "    print(\"Calibrating right camera...\")\n",
    "    ret_r, mtx_r, dist_r, rvecs_r, tvecs_r = cv2.calibrateCamera(\n",
    "        all_objpoints, all_imgpoints_right, img_shape, None, None\n",
    "    )\n",
    "    print(f\"  RMS error: {ret_r:.4f}\")\n",
    "    \n",
    "    # Good calibration typically has RMS < 1.0 pixel\n",
    "    if ret_l > 1.0 or ret_r > 1.0:\n",
    "        print(\"\\n⚠ WARNING: High RMS errors detected!\")\n",
    "        print(\"  This suggests problems with detection or board measurements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022a2ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 - Stereo calibration\n",
    "print(\"\\nPerforming stereo calibration...\")\n",
    "\n",
    "stereocalib_criteria = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, 100, 1e-5)\n",
    "flags = cv2.CALIB_FIX_INTRINSIC  # Use individual calibrations\n",
    "\n",
    "ret_stereo, mtx_l, dist_l, mtx_r, dist_r, R, T, E, F = cv2.stereoCalibrate(\n",
    "    all_objpoints,\n",
    "    all_imgpoints_left,\n",
    "    all_imgpoints_right,\n",
    "    mtx_l, dist_l,\n",
    "    mtx_r, dist_r,\n",
    "    img_shape,\n",
    "    criteria=stereocalib_criteria,\n",
    "    flags=flags\n",
    ")\n",
    "\n",
    "print(f\"Stereo RMS error: {ret_stereo:.4f}\")\n",
    "print(f\"\\nBaseline (translation): {np.linalg.norm(T):.4f} m\")\n",
    "print(f\"Translation vector: {T.flatten()}\")\n",
    "\n",
    "if ret_stereo > 1.0:\n",
    "    print(\"\\n⚠ WARNING: High stereo RMS error!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bf7bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8 - Stereo rectification\n",
    "print(\"Computing rectification maps...\")\n",
    "\n",
    "R1, R2, P1, P2, Q, roi_left, roi_right = cv2.stereoRectify(\n",
    "    mtx_l, dist_l,\n",
    "    mtx_r, dist_r,\n",
    "    img_shape,\n",
    "    R, T,\n",
    "    alpha=0,  # 0=crop to valid pixels, 1=keep all pixels\n",
    "    newImageSize=img_shape\n",
    ")\n",
    "\n",
    "map_left_x, map_left_y = cv2.initUndistortRectifyMap(\n",
    "    mtx_l, dist_l, R1, P1, img_shape, cv2.CV_32FC1\n",
    ")\n",
    "\n",
    "map_right_x, map_right_y = cv2.initUndistortRectifyMap(\n",
    "    mtx_r, dist_r, R2, P2, img_shape, cv2.CV_32FC1\n",
    ")\n",
    "\n",
    "print(f\"Left ROI: {roi_left}\")\n",
    "print(f\"Right ROI: {roi_right}\")\n",
    "\n",
    "def rectify_stereo_pair(img_left, img_right):\n",
    "    \"\"\"Apply rectification to a stereo pair.\"\"\"\n",
    "    rect_left = cv2.remap(img_left, map_left_x, map_left_y, cv2.INTER_LINEAR)\n",
    "    rect_right = cv2.remap(img_right, map_right_x, map_right_y, cv2.INTER_LINEAR)\n",
    "    return rect_left, rect_right\n",
    "\n",
    "print(\"Rectification ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebf3979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9 - Test rectification on a sample image\n",
    "test_idx = 0\n",
    "img_left_test = cv2.imread(left_images[test_idx])\n",
    "img_right_test = cv2.imread(right_images[test_idx])\n",
    "\n",
    "rect_left, rect_right = rectify_stereo_pair(img_left_test, img_right_test)\n",
    "\n",
    "# Draw horizontal lines to verify alignment\n",
    "def draw_horizontal_lines(img, num_lines=20):\n",
    "    img_lines = img.copy()\n",
    "    h, w = img.shape[:2]\n",
    "    for i in range(num_lines):\n",
    "        y = int(h * i / num_lines)\n",
    "        cv2.line(img_lines, (0, y), (w, y), (0, 255, 0), 1)\n",
    "    return img_lines\n",
    "\n",
    "rect_left_lines = draw_horizontal_lines(rect_left)\n",
    "rect_right_lines = draw_horizontal_lines(rect_right)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes[0, 0].imshow(cv2.cvtColor(img_left_test, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title('Original Left')\n",
    "axes[0, 1].imshow(cv2.cvtColor(img_right_test, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 1].set_title('Original Right')\n",
    "axes[1, 0].imshow(cv2.cvtColor(rect_left_lines, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 0].set_title('Rectified Left (with epipolar lines)')\n",
    "axes[1, 1].imshow(cv2.cvtColor(rect_right_lines, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 1].set_title('Rectified Right (with epipolar lines)')\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'rectification_test.jpg', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"If rectification is correct, horizontal lines should align across left/right images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d5bc68",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "The process of calibrating an image consists of mainly 3 steps: 1) find chessboard-corners in a dataset of images containing a chessboard. 2) Use the corner points to compute a camera matrix. 3) Use the camera matrix to undistort images.\n",
    "\n",
    "After setting some optimization parameters we can loop over all the images in the `imgs` folder and extract the checkerboard corners.\n",
    "\n",
    "Use any of the images in the folder `imgs` to extract the number of checkerboard corners there are on the checkerboard. Fill in the information in `nb_vertical` and `nb_horizontal` and look up the opencv [findChessboardCorners](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#ga93efa9b0aa890de240ca32b11253dd4a) function and implement it in the below code snippet ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f8cb1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loading success\n"
     ]
    }
   ],
   "source": [
    "# Define the chessboard dimensions for *each* type of chessboard you are using\n",
    "# If you have multiple identical chessboards, you only need one definition.\n",
    "\n",
    "square_size = 0.1 # m\n",
    "\n",
    "chessboard_sizes = {\n",
    "    'board1': (11, 7),  # eg big one on the left\n",
    "    'board2': (5, 7), #  eg smaller ones in the middle for example\n",
    "    'board3': (7, 5), # eg same as the prev one but on the side\n",
    "}\n",
    "square_sizes = {\n",
    "    'board1': square_size, # in your chosen unit\n",
    "    'board2': square_size,\n",
    "    'board3': square_size,\n",
    "}\n",
    "\n",
    "# Termination criteria for sub-pixel accuracy\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# Prepare object points for each board type\n",
    "objp_templates = {}\n",
    "for name, size in chessboard_sizes.items():\n",
    "    objp = np.zeros((size[0] * size[1], 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:size[0], 0:size[1]].T.reshape(-1, 2) * square_sizes[name]\n",
    "    objp_templates[name] = objp\n",
    "\n",
    "#print(objp_templates)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "# These will store detections from ALL boards found in a single image pair.\n",
    "all_objpoints = []\n",
    "all_imgpoints_left = []\n",
    "all_imgpoints_right = []\n",
    "\n",
    "# Get lists of image paths\n",
    "# Make sure your image pairs are correctly matched (e.g., left_001.jpg, right_001.jpg)\n",
    "raw_path = \"../data/34759_final_project_raw/\"\n",
    "left_raw_path = raw_path + \"calib/image_02/data/\"\n",
    "right_raw_path = raw_path + \"calib/image_03/data/\"\n",
    "\n",
    "left_images = sorted(glob.glob(left_raw_path + '*.png'))\n",
    "right_images = sorted(glob.glob(right_raw_path + '*.png'))\n",
    "\n",
    "\n",
    "\n",
    "if len(left_images) != len(right_images):\n",
    "    print(\"Error: Number of left and right images do not match!\")\n",
    "else:\n",
    "    print(\"Image loading success\")\n",
    "    #print(len(left_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70cf40f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n"
     ]
    }
   ],
   "source": [
    "iteration = 0\n",
    "logging_img = cv2.imread(left_images[0])\n",
    "logging_img = cv2.cvtColor(logging_img, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "#logging_img_corners = cv2.imread(left_images[0])\n",
    "\n",
    "logging_left = np.ndarray(logging_img.shape)\n",
    "logging_right = np.ndarray(logging_img.shape)\n",
    "\n",
    "#fig, ax = plt.subplots(nrows=len(left_images), ncols=1, figsize=(12, len(left_images) * 12))\n",
    "#ax = ax.ravel()\n",
    "\n",
    "for i in range(len(left_images) - 0):\n",
    "    # loop over every image\n",
    "    img_left = cv2.imread(left_images[i])\n",
    "    img_right = cv2.imread(right_images[i])\n",
    "            \n",
    "    gray_left = cv2.cvtColor(img_left, cv2.COLOR_BGR2GRAY) \n",
    "    gray_right = cv2.cvtColor(img_right, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    image_objpoints = []\n",
    "    image_corners_left = []\n",
    "    image_corners_right = []\n",
    "\n",
    "    for name, size in chessboard_sizes.items():\n",
    "        # iterating through the various chessboard sizes\n",
    "        do_while = 1\n",
    "        repeat = False\n",
    "        while do_while == 1 or repeat == True:\n",
    "            do_while = 0\n",
    "            # loop ever every single chessboard of the same size\n",
    "            #print(f\"%s found\", name)\n",
    "\n",
    "            h_l, w_l = gray_left.shape\n",
    "            h_r, w_r = gray_right.shape\n",
    "\n",
    "            manual_filter_start = (700, 300)\n",
    "            manual_filter_stop = (900, 400)\n",
    "            #manual_filter_start = (100, 200)\n",
    "            #manual_filter_stop = (200, 300)\n",
    "            \n",
    "            #gray_left = cv2.rectangle(gray_left, manual_filter_start, manual_filter_stop, (0, 0, 0), -1)\n",
    "            #gray_right = cv2.rectangle(gray_right, manual_filter_start, manual_filter_stop, (0, 0, 0), -1)\n",
    "\n",
    "            #logging_img = cv2.rectangle(logging_img, manual_filter_start, manual_filter_stop, (0, 0, 0), -1)\n",
    "\n",
    "\n",
    "            flags = 0#cv2.CALIB_CB_ADAPTIVE_THRESH | cv2.CALIB_CB_NORMALIZE_IMAGE | cv2.CALIB_CB_FILTER_QUADS\n",
    "            detected_boards_left, corners_left = cv2.findChessboardCornersSB(gray_left, size, flags)\n",
    "            detected_boards_right, corners_right = cv2.findChessboardCornersSB(gray_right, size, flags)\n",
    "\n",
    "\n",
    "            iteration += 1\n",
    "            if detected_boards_left:\n",
    "                #print(f\"detected on the left, %d\", iteration)\n",
    "                pass\n",
    "            \n",
    "            if detected_boards_left and detected_boards_right and corners_left.shape == corners_right.shape:\n",
    "                repeat = True\n",
    "                #print(\"detection\")\n",
    "                #repeat = False\n",
    "\n",
    "                # Refine corners\n",
    "                #corners_left = cv2.cornerSubPix(gray_left, corners_left, (11, 11), (-1, -1), criteria)\n",
    "                #corners_right = cv2.cornerSubPix(gray_right, corners_right, (11, 11), (-1, -1), criteria)\n",
    "\n",
    "\n",
    "                image_objpoints.append(objp_templates[name])\n",
    "                image_corners_left.append(corners_left)\n",
    "                image_corners_right.append(corners_right)\n",
    "\n",
    "                # cut the already detected chessboard out of the image\n",
    "                corner_left_expanded = ((corners_left[0][0]).astype(int), (corners_left[-1][0]).astype(int))\n",
    "                corner_right_expanded = ((corners_right[0][0]).astype(int), (corners_right[-1][0]).astype(int))\n",
    "\n",
    "                gray_left = cv2.rectangle(gray_left, corner_left_expanded[0], corner_left_expanded[1], (0, 0, 0), -1)\n",
    "                gray_right = cv2.rectangle(gray_right, corner_right_expanded[0], corner_right_expanded[1], (0, 0, 0), -1)\n",
    "\n",
    "                logging_left = cv2.drawChessboardCorners(gray_left, size, corners_left, True)\n",
    "                logging_right = cv2.drawChessboardCorners(gray_right, size, corners_right, True)\n",
    "\n",
    "                #logging_img = cv2.rectangle(gray_left, corner_left_expanded[0], corner_left_expanded[1], (0, 0, 0), -1)\n",
    "                #logging_img_corners = cv2.drawChessboardCorners(logging_img_corners, size, corners_left, True)\n",
    "\n",
    "            else:\n",
    "                repeat = False\n",
    "\n",
    "    if image_objpoints:\n",
    "                # Concatenate all boards found in this image\n",
    "        all_objpoints.append(np.vstack(image_objpoints))\n",
    "        all_imgpoints_left.append(np.vstack(image_corners_left))\n",
    "        all_imgpoints_right.append(np.vstack(image_corners_right)) \n",
    "\n",
    "        cv2.imwrite('left_' + str(i) + \".jpg\", logging_left)\n",
    "        cv2.imwrite('right_' + str(i) + \".jpg\", logging_right)\n",
    "\n",
    "        #ax[i] = plt.imshow(gray_left)\n",
    "        \n",
    "print(iteration)\n",
    "#fig, ax = plt.subplots(ncols=1, nrows=2, figsize=(14, 14))\n",
    "#ax[0].imshow(logging_img, cmap='gray')\n",
    "#ax[1].imshow(logging_img_corners)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85cd385b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left camera RMS reprojection error: 92.4372\n",
      "Right camera RMS reprojection error: 88.5031\n",
      "Stereo calibration RMS error: 3945.1013\n",
      "\n",
      "Rotation matrix:\n",
      "[[ 0.2281529   0.56253205 -0.79467223]\n",
      " [-0.68209411  0.67477463  0.28182765]\n",
      " [ 0.69476174  0.47774145  0.53765159]]\n",
      "\n",
      "Translation vector (baseline):\n",
      "[0.34230262 0.42577316 0.24155909]\n",
      "Baseline distance: 0.5973 m\n"
     ]
    }
   ],
   "source": [
    "img_shape_img = cv2.imread(left_images[0])\n",
    "img_shape_img = cv2.cvtColor(img_shape_img, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "img_shape = img_shape_img.shape\n",
    "img_shape = (img_shape[1], img_shape[0])\n",
    "\n",
    "ret_l, mtx_l, dist_l, rvecs_l, tvecs_l = cv2.calibrateCamera(\n",
    "    all_objpoints, \n",
    "    all_imgpoints_left, \n",
    "    img_shape, \n",
    "    None, \n",
    "    None\n",
    ")\n",
    "print(f\"Left camera RMS reprojection error: {ret_l:.4f}\")\n",
    "\n",
    "ret_r, mtx_r, dist_r, rvecs_r, tvecs_r = cv2.calibrateCamera(\n",
    "    all_objpoints, \n",
    "    all_imgpoints_right, \n",
    "    img_shape, \n",
    "    None, \n",
    "    None\n",
    ")\n",
    "print(f\"Right camera RMS reprojection error: {ret_r:.4f}\")\n",
    "\n",
    "# Stereo calibration\n",
    "stereocalib_criteria = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, 100, 1e-5)\n",
    "\n",
    "flags = cv2.CALIB_FIX_INTRINSIC  # Use individual calibrations as initial estimates\n",
    "# Alternative: flags = 0 to refine everything\n",
    "\n",
    "ret_stereo, mtx_l, dist_l, mtx_r, dist_r, R, T, E, F = cv2.stereoCalibrate(\n",
    "    all_objpoints,\n",
    "    all_imgpoints_left,\n",
    "    all_imgpoints_right,\n",
    "    mtx_l, dist_l,\n",
    "    mtx_r, dist_r,\n",
    "    img_shape,\n",
    "    criteria=stereocalib_criteria,\n",
    "    flags=flags\n",
    ")\n",
    "\n",
    "print(f\"Stereo calibration RMS error: {ret_stereo:.4f}\")\n",
    "print(f\"\\nRotation matrix:\\n{R}\")\n",
    "print(f\"\\nTranslation vector (baseline):\\n{T.flatten()}\")\n",
    "print(f\"Baseline distance: {np.linalg.norm(T):.4f} m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0525bb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left ROI: (0, 0, 0, 0)\n",
      "Right ROI: (0, 0, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "R1, R2, P1, P2, Q, roi_left, roi_right = cv2.stereoRectify(\n",
    "    mtx_l, dist_l,\n",
    "    mtx_r, dist_r,\n",
    "    img_shape,\n",
    "    R, T,\n",
    "    alpha=0,  # 0 = crop to valid pixels only, 1 = keep all pixels\n",
    "    newImageSize=img_shape\n",
    ")\n",
    "\n",
    "map_left_x, map_left_y = cv2.initUndistortRectifyMap(\n",
    "    mtx_l, dist_l, R1, P1, img_shape, cv2.CV_32FC1\n",
    ")\n",
    "\n",
    "map_right_x, map_right_y = cv2.initUndistortRectifyMap(\n",
    "    mtx_r, dist_r, R2, P2, img_shape, cv2.CV_32FC1\n",
    ")\n",
    "\n",
    "print(f\"Left ROI: {roi_left}\")\n",
    "print(f\"Right ROI: {roi_right}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d275e3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectify_stereo_pair(img_left: np.ndarray, img_right: np.ndarray):\n",
    "\n",
    "    \"\"\"Apply rectification to a stereo pair.\"\"\"\n",
    "    rect_left = cv2.remap(img_left, map_left_x, map_left_y, cv2.INTER_LINEAR)\n",
    "    rect_right = cv2.remap(img_right, map_right_x, map_right_y, cv2.INTER_LINEAR)\n",
    "    return rect_left, rect_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d0ca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(left_images[0])\n",
    "rect_img, _ = rectify_stereo_pair(img, img)\n",
    "\n",
    "plt.imshow(rect_img)\n",
    "#fig, ax = plt.subfigures(nrows=2, ncols=1, figsize=(14, 14))\n",
    "#ax[0] = plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0094ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "gray_img = cv2.imread(left_images[0])\n",
    "gray_img = cv2.cvtColor(gray_img, cv2.COLOR_BGR2GRAY)\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(all_objpoints, all_imgpoints_left, gray_img.shape[::-1], None, None)\n",
    "img = cv2.imread(left_images[0])\n",
    "h, w = img.shape[:2]\n",
    "newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d161bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# undistort\n",
    "dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(18,18))\n",
    "ax[0].imshow(img[...,[2,1,0]])\n",
    "ax[0].set_title('Original image')\n",
    "ax[1].imshow(dst[...,[2,1,0]])\n",
    "ax[1].set_title('Undistorted image')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8149df4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# crop the image\n",
    "x,y,w,h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(dst[...,[2,1,0]])\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
